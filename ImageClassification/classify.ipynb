{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification\n",
    "\n",
    "Notebook to produce the classification of regions within the images in northern scotland based on our training data.\n",
    "\n",
    "+ We will start by loading in the classification data, as [lat,lon] coordinates and a classification.\n",
    "+ We will also load in the GEE image, and extracting the appropriate bands, and creating new ones (NDWI, etc) if appropriate.\n",
    "\n",
    "+ We will have to split the classification data into a training set and a validation set.\n",
    "+ We will then train a GEE classifier using the training data, and verify its performance on the validation dataset.\n",
    "+ We will also proceed to classify the rest of the image tiles to determine the burnt regions of the image, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee initialisation\n",
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports and parameter initialisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import re\n",
    "\n",
    "import folium\n",
    "import geehydro\n",
    "import geemap\n",
    "\n",
    "\n",
    "# intial parameters for the program to run\n",
    "rng = np.random.default_rng(87347234) # seed the random number generator for consistency.\n",
    "classification_file = '../data/classification/master_classification.csv' # file from which the classification data is to be loaded.\n",
    "training_validation_ratio = 0.3 # ratio of classification data to be used in the training dataset. Keep low to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the classification data\n",
    "\n",
    "The file was created using the produce_classification.py script.\n",
    "\n",
    "The land classifications are:\n",
    "| Classification    | Value |\n",
    "|-------------------|-------|\n",
    "| Peatland          | 1     |\n",
    "| Burnt peatland    | 2     |\n",
    "| Cleared land      | 3     |\n",
    "| Agricultural land | 4     |\n",
    "| Plantation        | 5     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_training 267\n",
      "n_validation 622\n"
     ]
    }
   ],
   "source": [
    "########## STEP 1: Load in the classification data\n",
    "classification_data = pd.read_csv(classification_file)\n",
    "\n",
    "coords = classification_data['coords']\n",
    "classes = classification_data['classification']\n",
    "\n",
    "# The classification data needs to be converted into a ee.FeatureCollection object.\n",
    "# I will start by creating a list of ee.Feature objects. \n",
    "# These will then be shuffled and split to create the training and validation datasets.\n",
    "# These ee.Feature objects can then be converted into ee.FeatureCollection objects\n",
    "\n",
    "ee_Features = []\n",
    "\n",
    "# generate the list of ee.Features objects \n",
    "for point in zip(coords,classes):\n",
    "    # convert the string coordinate of the csv to an array\n",
    "    coord = point[0].split(',')\n",
    "    lon = float(coord[0][1:])\n",
    "    lat = float(coord[1][:-1])\n",
    "    coord = np.array([lon, lat])\n",
    "    \n",
    "    p = ee.Geometry.Point([*coord])\n",
    "    feat = ee.Feature(p, {'landcover':point[1]})\n",
    "    ee_Features.append(feat)\n",
    "\n",
    "# randomly shuffle and then split the ee.Features list\n",
    "rng.shuffle(ee_Features)\n",
    "split_index = np.round( len(ee_Features) * training_validation_ratio ).astype(int)\n",
    "\n",
    "ee_Features_training = ee_Features[:split_index]\n",
    "ee_Features_validation = ee_Features[split_index:]\n",
    "\n",
    "print('n_training', len(ee_Features_training))\n",
    "print('n_validation', len(ee_Features_validation))\n",
    "\n",
    "# create the feature collections for the training and validation data\n",
    "ee_training = ee.FeatureCollection(ee_Features_training)\n",
    "ee_validation = ee.FeatureCollection(ee_Features_validation)\n",
    "\n",
    "#print(ee_training.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the GEE image tiles\n",
    "\n",
    "We need to load in the GEE image tiles which we want to perform the classification on.\n",
    "\n",
    "We will do this by laoding in the data from the [WHICH SATELLITE???] satellite and filtering the images based on date, region, cloudiness, etc.\n",
    "We will display an image of the area on a folium map to check we have the correct area.\n",
    "\n",
    "From this we can generate the NDWI and other bands that we can add to the image collection.\n",
    "We'll then extract a singular image to train our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert the geojson to ee.Geometry()\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/SENSE/lib/python3.8/site-packages/geemap/common.py:1242\u001b[0m, in \u001b[0;36mgeojson_to_ee\u001b[0;34m(geo_json, geodesic, encoding)\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[39m# geo_json[\"geodesic\"] = geodesic\u001b[39;00m\n\u001b[0;32m-> 1242\u001b[0m \u001b[39mif\u001b[39;00m geo_json[\u001b[39m\"\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFeatureCollection\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m geo_json[\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m###############\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m## CREATE IMAGE COLLECTION\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m################\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef maskS2clouds(image):\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m    qa = image.select('QA60')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m    return image.updateMask(mask).divide(10000).copyProperties(image, ['system:time_start'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m ROI \u001b[39m=\u001b[39m geemap\u001b[39m.\u001b[39;49mgeojson_to_ee(\u001b[39m'\u001b[39;49m\u001b[39mdata/ROI/BogsOnFire_ROI.geojson\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maddBANDS\u001b[39m(image):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eeasm/Documents/SENSE/BogsOnFire/ImageClassification/classify.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     ndvi \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mnormalizedDifference([\u001b[39m'\u001b[39m\u001b[39mB8\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mB4\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mrename(\u001b[39m'\u001b[39m\u001b[39mNDVI\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SENSE/lib/python3.8/site-packages/geemap/common.py:1270\u001b[0m, in \u001b[0;36mgeojson_to_ee\u001b[0;34m(geo_json, geodesic, encoding)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1269\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCould not convert the geojson to ee.Geometry()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1270\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(e)\n",
      "\u001b[0;31mException\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## CREATE IMAGE COLLECTION\n",
    "################\n",
    "'''\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "    #Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "    #Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).and(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    return image.updateMask(mask).divide(10000).copyProperties(image, ['system:time_start'])\n",
    "'''\n",
    "ROI = geemap.geojson_to_ee('data/ROI/BogsOnFire_ROI.geojson')\n",
    "\n",
    "def addBANDS(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    ndwi = image.normalizedDifference(['B8', 'B12']).rename('NDWI')\n",
    "    return image.addBands(ndvi).addBands(ndwi)\n",
    "\n",
    "dataset = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterDate('2017-01-01', '2022-11-01').filterBounds(ROI).filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',30))\n",
    "#.map(maskS2clouds);\n",
    "                  \n",
    "                   \n",
    "dataset = dataset.map(addBANDS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2018-01-01', '2018-02-01', '2018-03-01', '2018-04-01',\n",
      "               '2018-05-01', '2018-06-01', '2018-07-01', '2018-08-01',\n",
      "               '2018-09-01', '2018-10-01', '2018-11-01', '2018-12-01',\n",
      "               '2019-01-01', '2019-02-01', '2019-03-01', '2019-04-01',\n",
      "               '2019-05-01', '2019-06-01', '2019-07-01', '2019-08-01',\n",
      "               '2019-09-01', '2019-10-01', '2019-11-01', '2019-12-01',\n",
      "               '2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01',\n",
      "               '2020-05-01', '2020-06-01', '2020-07-01', '2020-08-01',\n",
      "               '2020-09-01', '2020-10-01', '2020-11-01', '2020-12-01',\n",
      "               '2021-01-01', '2021-02-01', '2021-03-01', '2021-04-01',\n",
      "               '2021-05-01', '2021-06-01', '2021-07-01', '2021-08-01',\n",
      "               '2021-09-01', '2021-10-01', '2021-11-01', '2021-12-01',\n",
      "               '2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01',\n",
      "               '2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01',\n",
      "               '2022-09-01', '2022-10-01', '2022-11-01'],\n",
      "              dtype='datetime64[ns]', freq='MS')\n"
     ]
    }
   ],
   "source": [
    "dates = pd.date_range('2018-01-01','2022-11-01', freq = 'MS')\n",
    "imgs = []\n",
    "\n",
    "def collectYearN(dates):\n",
    "    for i in range(len(dates)-1):\n",
    "        start = dates[i]\n",
    "        end = dates[i+1]\n",
    "        #start = ee.Date.fromYMD(year,month,1)\n",
    "        #end = start.advance(1,'month')\n",
    "        imgs.append(dataset.filterDate(start,end).reduce(ee.Reducer.median()).set({'date':start}))\n",
    "\n",
    "merged_years_dataset = ee.ImageCollection(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the individual images and turn them into an image collection\n",
    "num_images = 55\n",
    "\n",
    "load_location = 'users/RNIng/BogsOnFire/{}'\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    assetID = '{}'.format(i)\n",
    "    imgs.append(ee.Image(assetID))\n",
    "\n",
    "merged_years_dataset = ee.ImageCollection(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to start by loading in the image collection upon which we want to perform our classification.\n",
    "\n",
    "#ee_ImCollection = ee.ImageCollection('')\n",
    "\n",
    "Map = folium.Map(location=[-3.893, 58.571], zoom_start=10);\n",
    "\n",
    "merged_years_dataset = ee.ImageCollection('users/RNIng/BogsOnFire/monthly_image_timeseries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3956743669.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [30]\u001b[0;36m\u001b[0m\n\u001b[0;31m    finalCollection = merged_years_dataset.map(function(image){\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''Fran's code\n",
    "\n",
    "Need to determine how we will load in the ee.ImageCollection object, here called merged_years_dataset\n",
    "Will also need to create the Map object. Not sure if this is a folium or ee object...\n",
    "'''\n",
    "\n",
    "merged_years_dataset = ee.ImageCollection('users/RNIng/BogsOnFire/monthly_image_timeseries')\n",
    "\n",
    "def finalCollectionFn(image):\n",
    "  return image.visualize({'bands': ['B3_median', 'B2_median', 'B1_median'], 'min': 200, 'max': 5000, 'gamma': 1.2})\n",
    "\n",
    "finalCollection = merged_years_dataset.map(finalCollectionFn)\n",
    "\n",
    "\n",
    "visualization = {\n",
    "  'min': 200.365,\n",
    "  'max': 2965.885,\n",
    "  'bands': ['B3_median', 'B2_median', 'B1_median'],\n",
    "};\n",
    "\n",
    "Map = folium.Map(location=[-3.893, 58.571], zoom_start=10);\n",
    "\n",
    "Map.addLayer(merged_years_dataset.median(), visualization, 'RGB');\n",
    "####\n",
    "# CREATE/TRAIN THE CLASSIFIER\n",
    "####\n",
    "DatasetList = ee.ImageCollection(merged_years_dataset).toList(47);\n",
    "ClassificationImage = ee.ImageCollection(ee.List(DatasetList).get(4));\n",
    "print('ClassificationImage: ', ClassificationImage);\n",
    "bands = [\"B1_median\", \"B2_median\", \"B3_median\", \"B4_median\",\n",
    "             \"B5_median\", \"B6_median\", \"B7_median\", \"B8_median\",\n",
    "             \"B8A_median\", \"B9_median\", \"B11_median\", \"B12_median\",\n",
    "             \"AOT_median\", \"WVP_median\", \"SCL_median\", \"TCI_R_median\",\n",
    "             \"TCI_G_median\", \"TCI_B_median\", \"MSK_CLDPRB_median\",\n",
    "             \"MSK_SNWPRB_median\", \"QA10_median\", \"QA20_median\",\n",
    "             \"QA60_median\", \"NDVI_median\", \"NDWI_median\"];\n",
    "classifier = ee.Classifier.smileRandomForest({numberOfTrees: 200,\n",
    "                                                  minLeafPopulation: 1,\n",
    "                                                  bagFraction: 0.5});\n",
    "label = 'Landcover'; #Change with name of ground data\n",
    "Data = ee_training;\n",
    "training = ClassificationImage.select(bands).sampleRegions({\n",
    "  'collection': Data,\n",
    "  'properties': [label],\n",
    "  'scale': 30,\n",
    "  'tileScale': 6\n",
    "});\n",
    "\n",
    "'''Random partitioning of test/validation data. I've already performed this above.\n",
    "withRandom = training.randomColumn('random');\n",
    "trainingPartition = withRandom.filter(ee.Filter.lt('random', 0.6));\n",
    "testvalPartition = withRandom.filter(ee.Filter.gte('random', 0.6));\n",
    "testvalwithRandom = testvalPartition.randomColumn('ran1dom');\n",
    "testingPartition = testvalwithRandom.filter(ee.Filter.lt('ran1dom', 0.5));\n",
    "validationPartition = testvalwithRandom.filter(ee.Filter.gte('ran1dom', 0.5));\n",
    "'''\n",
    "#print('trainingPartition: ', trainingPartition);\n",
    "#print('testingPartition: ', testingPartition);\n",
    "#print('validationPartition: ', validationPartition);\n",
    "#Trained with X% of our data.\n",
    "trainedClassifier = classifier.train(ee_training, label, bands);\n",
    "#Classify the image with the same bands used for training.\n",
    "trainedClassified = ClassificationImage.select(bands).classify(trainedClassifier);\n",
    "####\n",
    "#ACCURACY ASSESSMENT OF CLASSIFICATION\n",
    "####\n",
    "#Get a confusion matrix representing resubstitution accuracy.\n",
    "trainedAccuracy = trainedClassifier.confusionMatrix();\n",
    "print('trained error matrix: ', trainedAccuracy);\n",
    "print('trained overall accuracy: ', trainedAccuracy.accuracy());\n",
    "#Classify the test FeatureCollection.\n",
    "tested = ee_validation.classify(trainedClassifier);\n",
    "#Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = tested.errorMatrix(label, 'classification');\n",
    "print('Tested overall accuracy: ', testAccuracy.accuracy());\n",
    "\n",
    "'''Exporting images, not strictly necessary at this point?\n",
    "Export.table.toDrive(tested, \"Malitested\", \"TLLGExports\");\n",
    "print('trainedClassified', trainedClassified);\n",
    "Export.image.toDrive({\n",
    "  image: trainedClassified,\n",
    "  description: 'trainedClassified',\n",
    "  scale: 30,\n",
    "  region: ROI\n",
    "});\n",
    "'''\n",
    "Map.addLayer(trainedClassified, {bands: ['classification'], min: 1, max: 6}, 'trainedClassifiedFor');\n",
    "'''\n",
    "///#VALIDATION\n",
    "#Classify the test FeatureCollection.\n",
    "validation = validationPartition.classify(trainedClassifier);\n",
    "#Get a confusion matrix representing expected accuracy.\n",
    "validationAccuracy = validation.errorMatrix(label, 'classification');\n",
    "print('Validation overall accuracy: ', validationAccuracy.accuracy());\n",
    "'''\n",
    "####\n",
    "#CLASSIFY THE IMAGE COLLECTION\n",
    "####\n",
    "def ClassifyIC(image):\n",
    "    classified = image.classify(trainedClassifier)\n",
    "    return image.addBands(classified)\n",
    "\n",
    "  \n",
    "collection = merged_years_dataset;\n",
    "collectionWC = collection.map(ClassifyIC);\n",
    "print('collectionWC: ', collectionWC);\n",
    "####\n",
    "#TIME SERIES OF NDVI/NDWI\n",
    "####\n",
    "'''\n",
    "collection = merged_years_dataset;\n",
    "NDVI = collection.select(['NDVI']);\n",
    "#NDVImed = NDVI.median();\n",
    "#Create palettes for display of NDVI\n",
    "ndvi_pal = ['#D73027', '#F46D43', '#FDAE61', '#FEE08B', '#D9EF8B',\n",
    "'#A6D96A'];\n",
    "#Create a time series chart.\n",
    "plotNDVI = ui.Chart.image.seriesByRegion(collection, ROI, ee.Reducer.mean(),\n",
    "'NDVI_median',500,'system:time_start', 'system:index')\n",
    "              .setChartType('LineChart').setOptions({\n",
    "                title: 'NDVI short-term time series',\n",
    "                hAxis: {title: 'Date'},\n",
    "                vAxis: {title: 'NDVI'}\n",
    "});\n",
    "print(plotNDVI);\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('SENSE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20c25a4cfcb392cc3cc6b7adbf61eb80ed688ffa55711566883c582774ecc0b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
